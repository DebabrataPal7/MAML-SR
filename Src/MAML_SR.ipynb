{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4kGEqt8uEIS"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import Tensor\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "from collections import OrderedDict\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Subset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import random\n",
    "from google.colab import files\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from torch.autograd import Variable\n",
    "import skimage.segmentation\n",
    "import skimage.io\n",
    "import skimage \n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import skimage.segmentation\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "from skimage import feature\n",
    "from skimage import filters\n",
    "import copy\n",
    "import sklearn\n",
    "import torchvision\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imageio\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvFlkC28w8Rx"
   },
   "outputs": [],
   "source": [
    "# Image Augmentations\n",
    "def randomHueSaturationValue(\n",
    "    image,\n",
    "    hue_shift_limit=(-40, 40),\n",
    "    sat_shift_limit=(-10, 10),\n",
    "    val_shift_limit=(-20, 20),\n",
    "    u=0.5,\n",
    "):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(image)\n",
    "        hue_shift = np.random.randint(\n",
    "            hue_shift_limit[0], hue_shift_limit[1] + 1)\n",
    "        hue_shift = np.uint8(hue_shift)\n",
    "        h += hue_shift\n",
    "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "        s = cv2.add(s, sat_shift)\n",
    "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "        v = cv2.add(v, val_shift)\n",
    "        image = cv2.merge((h, s, v))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    " \n",
    "    return image\n",
    " \n",
    " \n",
    "def randomShiftScaleRotate(\n",
    "    image,\n",
    "    shift_limit=(-0.1, 0.1),\n",
    "    scale_limit=(-0.1, 0.1),\n",
    "    aspect_limit=(-0.1, 0.1),\n",
    "    rotate_limit=(-90, 90),\n",
    "    borderMode=cv2.BORDER_CONSTANT,\n",
    "    u=0.5,\n",
    "):\n",
    "    if np.random.random() < u:\n",
    "        height, width, channel = image.shape\n",
    " \n",
    "        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])\n",
    "        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "        sx = scale * aspect / (aspect ** 0.5)\n",
    "        sy = scale / (aspect ** 0.5)\n",
    "        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
    "        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
    " \n",
    "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    " \n",
    "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height]])\n",
    "        box1 = box0 - np.array([width / 2, height / 2])\n",
    "        box1 = np.dot(box1, rotate_matrix.T) + np.array(\n",
    "            [width / 2 + dx, height / 2 + dy]\n",
    "        )\n",
    " \n",
    "        box0 = box0.astype(np.float32)\n",
    "        box1 = box1.astype(np.float32)\n",
    "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "        image = cv2.warpPerspective(\n",
    "            image,\n",
    "            mat,\n",
    "            (width, height),\n",
    "            flags=cv2.INTER_NEAREST,\n",
    "            borderMode=borderMode,\n",
    "            borderValue=(0, 0, 0),\n",
    "        )\n",
    " \n",
    "    return image\n",
    " \n",
    " \n",
    "def randomHorizontalFlip(image, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 1)\n",
    " \n",
    "    return image\n",
    " \n",
    "def randomVerticleFlip(image, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 0)\n",
    " \n",
    "    return image \n",
    " \n",
    "def randomRotate90(image, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = np.rot90(image)\n",
    " \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2a0ofnVh6r-f"
   },
   "outputs": [],
   "source": [
    "# Dataset Definition\n",
    "class Train(Dataset):\n",
    "  def __init__(self,train_image_paths,image_dimension,lr_dimension):\n",
    "    self.image_path=train_image_paths\n",
    "    self.dim=image_dimension\n",
    "    self.lr_dim=lr_dimension\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.image_path)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    image=imageio.imread(self.image_path[idx])\n",
    "    image=cv2.resize(image,(256,256))\n",
    "    # augmentaions applied\n",
    "    image=randomHueSaturationValue(image)\n",
    "    image=randomShiftScaleRotate(image)\n",
    "    image=randomVerticleFlip(image)\n",
    "    image=randomHorizontalFlip(image)\n",
    "    image=randomRotate90(image)\n",
    "\n",
    "    ground_truth=torch.from_numpy(image.copy()).permute(2,0,1)\n",
    "    input_image=cv2.resize(image,(self.lr_dim,self.lr_dim),interpolation=cv2.INTER_AREA)   \n",
    "    input_image=cv2.resize(input_image,(self.dim,self.dim)) \n",
    "    input_image=torch.from_numpy(input_image.copy()).permute(2,0,1)\n",
    "\n",
    "    return input_image/255.0, ground_truth/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acJYToRc61i2"
   },
   "outputs": [],
   "source": [
    "class Test(Dataset):\n",
    "  def __init__(self,test_image_paths,image_dimension,lr_dimension):\n",
    "    self.image_path=test_image_paths\n",
    "    self.dim=image_dimension\n",
    "    self.lr_dim=lr_dimension\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.image_path)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    image=imageio.imread(self.image_path[idx])\n",
    "    image=cv2.resize(image,(256,256))\n",
    "    ground_truth=torch.from_numpy(image.copy()).permute(2,0,1)\n",
    "    input_image=cv2.resize(image,(self.lr_dim,self.lr_dim),interpolation=cv2.INTER_AREA)  \n",
    "    input_image=cv2.resize(input_image,(self.dim,self.dim)) \n",
    "    input_image=torch.from_numpy(input_image.copy()).permute(2,0,1)\n",
    "\n",
    "    return input_image/255.0,ground_truth/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzewOmk862NW",
    "outputId": "bb90b848-98b3-4141-c5f2-e4ceaaa41bc4"
   },
   "outputs": [],
   "source": [
    "train_ds=Train(train_image_paths,256,86)\n",
    "test_ds=Test(test_image_paths,256,86)\n",
    "\n",
    "train_dl=DataLoader(train_ds,batch_size=4,shuffle=True,num_workers=2)\n",
    "test_dl=DataLoader(test_ds,batch_size=4,shuffle=False,num_workers=2)\n",
    "\n",
    "print(len(train_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAML-SR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KA7jquTruIK"
   },
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    \"\"\" nn.Upsample is deprecated \"\"\"\n",
    "    def __init__(self, scale_factor, mode=\"bilinear\"):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode, align_corners=True, recompute_scale_factor=True)\n",
    "        return x  \n",
    "\n",
    "\n",
    "class Upsample_meta(nn.Module):\n",
    "    \"\"\" nn.Upsample is deprecated \"\"\"\n",
    "    def __init__(self, scale_factor,input_features,output_features, mode=\"bilinear\"):\n",
    "        super(Upsample_meta, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.conv=nn.Conv2d(input_features,output_features,kernel_size=1,stride=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode, align_corners=True, recompute_scale_factor=True)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLjn-NqCBO6c"
   },
   "outputs": [],
   "source": [
    "# Channel attention\n",
    "class Channel_Attention(nn.Module):\n",
    "  def __init__(self,num_channels):\n",
    "    super(Channel_Attention,self).__init__()\n",
    "    self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "    self.conv=nn.Conv2d(num_channels*2,num_channels,kernel_size=1,stride=1,bias=False)\n",
    "\n",
    "  def forward(self,x):\n",
    "    avg_out=self.avgpool(x)\n",
    "    max_out=self.maxpool(x)\n",
    "    att_map=self.conv(torch.cat((avg_out,max_out),1))\n",
    "    return x*torch.sigmoid(att_map)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeOPeXKSpDVa"
   },
   "outputs": [],
   "source": [
    "# Spatial Attention\n",
    "class Spatial_Attention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Spatial_Attention,self).__init__()\n",
    "    self.conv1=nn.Conv2d(2,1,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "\n",
    "  def forward(self,x):\n",
    "    avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "    max_out, _ = torch.max(x, dim=1, keepdim=True)      \n",
    "    att_map = torch.cat([avg_out, max_out], dim=1)\n",
    "    att_map = self.conv1(att_map)\n",
    "    return x*torch.sigmoid(att_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brXXs2wfJ3p-"
   },
   "outputs": [],
   "source": [
    "# Attention Blocks\n",
    "class attention_block(nn.Module):\n",
    "  def __init__(self,num_sets,fsets,lsets): #fsets--> channel sum of all multiscale features; #lsets--> channel size of the specific level of the network; #num_sets--> num of levels whose features are taken\n",
    "    super(attention_block,self).__init__()\n",
    "    self.upsampler=nn.ModuleList([Upsample_meta(2**i,fsets[i],lsets) for i in range(1,num_sets)])\n",
    "    self.sp=Spatial_Attention()\n",
    "    self.ch=Channel_Attention(num_sets*lsets)\n",
    "    self.conv=nn.Conv2d(2*num_sets*lsets,lsets,kernel_size=3,stride=1,padding=1,dilation=1)\n",
    "    self.bn=nn.BatchNorm2d(lsets)\n",
    "\n",
    "  def forward(self,x1,data):\n",
    "    for i in range(len(data)):\n",
    "      data[i]=self.upsampler[i](data[i])\n",
    "    data=torch.cat(data,1)\n",
    "    x=torch.cat((x1,data),1)\n",
    "    x_sp=self.sp(x)\n",
    "    x_ch=self.ch(x)\n",
    "    x_out = x1 + self.bn(self.conv(torch.cat((x_sp,x_ch),1)))\n",
    "    return F.relu(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnZU7BnuJ30G"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=True, bias=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        dim_out = planes\n",
    "        self.stride = stride\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=bias)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(dim_out, dim_out, kernel_size=(3, 3),\n",
    "                               stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        if downsample == True:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=bias),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        elif isinstance(downsample, nn.Module):\n",
    "            self.downsample = downsample\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        out = self.bn2(x)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class fcn_out(nn.Module):\n",
    "    def __init__(self,input_channels,upsample_factor):\n",
    "        super(fcn_out,self).__init__()\n",
    "        self.conv1=nn.Conv2d(input_channels,64,kernel_size=3,stride=1,padding=3//2,dilation=1)\n",
    "        self.norm1=nn.BatchNorm2d(64)\n",
    "        self.upsample=Upsample(upsample_factor)\n",
    "        self.conv2=nn.Conv2d(64,64,kernel_size=3,stride=1,padding=3//2,dilation=1)\n",
    "        self.conv3=nn.Conv2d(64,3,kernel_size=1,stride=1,padding=0,dilation=1)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.norm1(self.conv1(x)))\n",
    "        x=F.relu(self.conv2(self.upsample(x)))\n",
    "        x=self.conv3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "class MAMLSR(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MAMLSR, self).__init__()\n",
    "\n",
    "        self.res_conv = ResidualBlock\n",
    "\n",
    "        self.down1 = self.res_conv(num_channels, 32)\n",
    "        self.down2 = self.res_conv(32, 64)\n",
    "        self.down3 = self.res_conv(64, 128)\n",
    "        self.down4 = self.res_conv(128, 256)\n",
    "\n",
    "        self.attn1 = attention_block(4,[32,64,128,256],32)\n",
    "        self.attn2 = attention_block(3,[64,128,256],64)\n",
    "        self.attn3 = attention_block(2,[128,256],128)\n",
    "\n",
    "        self.bridge = self.conv_stage(256, 256)\n",
    "        \n",
    "\n",
    "        self.up4 = self.res_conv(1024//2, 512//2)\n",
    "        self.up3 = self.res_conv(512//2, 256//2)\n",
    "        self.up2 = self.res_conv(256//2, 128//2)\n",
    "        self.up1 = self.res_conv(128//2, 64//2)\n",
    "\n",
    "        self.trans4 = self.upsample(512//2, 512//2)\n",
    "        self.trans3 = self.upsample(512//2, 256//2)\n",
    "        self.trans2 = self.upsample(256//2, 128//2)\n",
    "        self.trans1 = self.upsample(128//2, 64//2)\n",
    "\n",
    "        self.conv_last = nn.Sequential(\n",
    "            nn.Conv2d(64//2, 3, 3, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self.fcn3=fcn_out(512*2//2,8)\n",
    "        self.fcn2=fcn_out(256*2//2,4)\n",
    "        self.fcn1=fcn_out(128*2//2,2)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def conv_stage(self, dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size,\n",
    "                      stride=stride, padding=padding, bias=bias),\n",
    "            nn.BatchNorm2d(dim_out),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # nn.ReLU(),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size,\n",
    "                      stride=stride, padding=padding, bias=bias),\n",
    "            nn.BatchNorm2d(dim_out),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def upsample(self, ch_coarse, ch_fine):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.down1(x)\n",
    "        conv2_out = self.down2(self.max_pool(conv1_out))\n",
    "        conv3_out = self.down3(self.max_pool(conv2_out))\n",
    "        conv4_out = self.down4(self.max_pool(conv3_out))    # ch = 512  \n",
    "\n",
    "        # multiscale attention process of the encoder's features\n",
    "        conv1_out=self.attn1(conv1_out,[conv2_out,conv3_out,conv4_out])\n",
    "        conv2_out=self.attn2(conv2_out,[conv3_out,conv4_out])\n",
    "        conv3_out=self.attn3(conv3_out,[conv4_out])\n",
    "\n",
    "        out = self.bridge(self.max_pool(conv4_out))         # ch = 512  \n",
    "\n",
    "        out = self.trans4(out)\n",
    "        out_4 = self.fcn3(torch.cat((out, conv4_out), 1))\n",
    "        out = self.up4(torch.cat((out, conv4_out), 1))\n",
    "\n",
    "        out = self.trans3(out)\n",
    "        out_3 = self.fcn2(torch.cat((out, conv3_out), 1))\n",
    "        out = self.up3(torch.cat((out, conv3_out), 1))\n",
    "\n",
    "        out = self.trans2(out)\n",
    "        out_2 = self.fcn1(torch.cat((out, conv2_out), 1))\n",
    "        out = self.up2(torch.cat((out, conv2_out), 1))\n",
    "        \n",
    "        out = self.up1(torch.cat((self.trans1(out), conv1_out), 1))\n",
    "        out = self.conv_last(out)\n",
    "\n",
    "        return out, out_2, out_3, out_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6n3sBHNwBA_"
   },
   "outputs": [],
   "source": [
    "model = MAMLSR().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpfKiDNcl9qF"
   },
   "outputs": [],
   "source": [
    "loss_l1=nn.L1Loss()\n",
    "cos=nn.CosineSimilarity()\n",
    "\n",
    "def loss_cosine(input,target):\n",
    "  sim=cos(input,target)\n",
    "  sim=sim.mean((1,2))\n",
    "  return sim.mean()\n",
    "\n",
    "def loss_deep1(pred2,pred3,pred4,target):\n",
    "  l1,l2,l3=1,1,1  # change lamdas according to need\n",
    "  loss2=loss_l1(pred2,target)\n",
    "  loss3=loss_l1(pred3,target)\n",
    "  loss4=loss_l1(pred4,target)\n",
    "  return l1*loss2+l2*loss3+l3*loss4\n",
    "\n",
    "def loss_fn(output,target):\n",
    "  loss=loss_l1(output,target)\n",
    "  return loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-training MAML-SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiA_BByAV8wu"
   },
   "outputs": [],
   "source": [
    "# Meta Training Step\n",
    "def train_meta(model,train_dl,learn):\n",
    "  opt_cl=torch.optim.Adam(model.parameters(),lr=learn)  # can change to SGD\n",
    "  loss_1=0.0 # loss visualization of the first step of optimization\n",
    "  loss_2=0.0 # loss visualization of the second step of optimization\n",
    "  for a,b in train_dl:\n",
    "    a=a.float()\n",
    "    b=b.float()\n",
    "    output,pred2,pred3,pred4=model(a.cuda())\n",
    "    loss3=loss_deep1(pred2,pred3,pred4,b.cuda())\n",
    "    loss_1 = loss_1 + loss3\n",
    "\n",
    "    # First Step of Multi-scale Optimization\n",
    "    opt_cl.zero_grad()\n",
    "    loss3.backward()\n",
    "    opt_cl.step()\n",
    "\n",
    "    # Second stage of optimization\n",
    "    output,_,_,_=model(a.cuda())\n",
    "    loss_final=loss_fn(output,b.cuda())\n",
    "    loss_2 = loss_2 + loss_final\n",
    "    opt_cl.zero_grad()\n",
    "    loss_final.backward()\n",
    "    opt_cl.step()\n",
    "  \n",
    "  loss_1=loss_1/len(train_dl)\n",
    "  loss_2=loss_2/len(train_dl)\n",
    "  return model, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POph9T7v73wX"
   },
   "outputs": [],
   "source": [
    "# Training Step\n",
    "\n",
    "def step_train_epochs(model,train_dl,epochs,learn,path):\n",
    "  max_acc=0.0\n",
    "  for i in range(1,epochs+1):\n",
    "    model,loss_1,loss_2=train_meta(model,train_dl,learn)\n",
    "    print(\"Epoch: \" +str(i))\n",
    "    print(\"Train_loss_meta_step1: \" + str(loss_1.detach().cpu()) + \" Train_loss_meta_step2: \" + str(loss_2.detach().cpu()))\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    path_final=os.path.join(path,\n",
    "                                   f\"epoch{i}_loss1{loss_1.detach().cpu():.4f}_loss2{loss_2.detach().cpu():.4f}.pth\")\n",
    "    torch.save(model.state_dict(), path_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gd31vL1l86L_"
   },
   "outputs": [],
   "source": [
    "%mkdir sisr\n",
    "step_train_epochs(model,train_dl,20,0.001,'/content/sisr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-testing MAML-SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQXVAYIxihXJ"
   },
   "outputs": [],
   "source": [
    "# Meta Testing Step\n",
    "def test_meta(model,test_dl,learn):\n",
    "  opt_cl=torch.optim.Adam(model.parameters(),lr=learn)\n",
    "  opsnr=0\n",
    "  ossim=0  \n",
    "  for a,b in test_dl:  # test_dl is dataloader which loads data in shape (16,3,256,256) \n",
    "    a=a.float()\n",
    "    b=b.float()\n",
    "    with torch.no_grad():\n",
    "      sr_init,sr2,_,_=model(a.cuda())\n",
    "    psnr_init,ssim_init=0,0\n",
    "\n",
    "    while True:\n",
    "      s1,s2,_,_=model(a.cuda())\n",
    "      loss=loss_fn(s1,s2)\n",
    "      opt_cl.zero_grad()\n",
    "      loss.backward()\n",
    "      opt_cl.step()\n",
    "\n",
    "      sr_p,_,_,_=model(a.cuda())\n",
    "      psnr_pr=tf.image.psnr(sr_p.detach().cpu().numpy(),sr_init.detach().cpu().numpy(),max_val=1.0)\n",
    "      psnr_pr=tf.reduce_mean(psnr_pr)\n",
    "      ssim_pr=tf.image.ssim(sr_p.detach().cpu().numpy().transpose(0,2,3,1),sr_init.detach().cpu().numpy().transpose(0,2,3,1),max_val=1.0)\n",
    "      ssim_pr=tf.reduce_mean(ssim_pr)\n",
    "      if psnr_pr>psnr_init and ssim_pr>ssim_init:\n",
    "        psnr_init=psnr_pr\n",
    "        ssim_init=ssim_pr\n",
    "        sr_init=sr_p\n",
    "      elif psnr_pr<psnr_init and ssim_pr<ssim_init:\n",
    "        break\n",
    "\n",
    "    psnr_final=tf.image.psnr(sr_init.detach().cpu().numpy(),b.numpy(),max_val=1.0)   \n",
    "    psnr_final=tf.reduce_mean(psnr_final) \n",
    "    ssim_final=tf.image.ssim(sr_init.detach().cpu().numpy().transpose(0,2,3,1),b.numpy().transpose(0,2,3,1),max_val=1.0)\n",
    "    ssim_final=tf.reduce_mean(ssim_final)\n",
    "    opsnr=opsnr+psnr_final\n",
    "    ossim=ossim+ssim_final\n",
    "  opsnr=opsnr/len(test_dl)\n",
    "  ossim=ossim/len(test_dl)\n",
    "  return model,opsnr,ossim    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cg_v4h83-3Ge"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ID0EcqBy-ONG"
   },
   "outputs": [],
   "source": [
    "# Meta Testing Step\n",
    "model,opsnr,ossim=test_meta(model,train_dl,0.001)\n",
    "print(\"OPSNR: \" + str(opsnr))\n",
    "print(\"OSSIM: \" + str(ossim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8bPpnY2LRTx"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'final_model_sisrx4.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
